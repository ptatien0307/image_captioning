{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRendWR3xGsU",
        "outputId": "cc320e6a-d1b3-4c9d-9e80-55fbf8bc7986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1T29Y68hwqYe4aONgWDX4qeaf22winbNJ/ImageCaptioning\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ImageCaptioning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9hdFKaqratk",
        "outputId": "29791544-6d53-4ce4-e735-abef8b437f6c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "H68M8TEMxT54"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense, Dropout, add, RepeatVector, Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from keras import Input\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY1QLpUixcq-"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "CiczDg15vzMO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b489b09e-3f4f-46ee-9792-d019ea31c94d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           image                                            caption\n",
              "0      1000268201_693b08cb0e.jpg  A child in a pink dress is climbing up a set o...\n",
              "1      1000268201_693b08cb0e.jpg              A girl going into a wooden building .\n",
              "2      1000268201_693b08cb0e.jpg   A little girl climbing into a wooden playhouse .\n",
              "3      1000268201_693b08cb0e.jpg  A little girl climbing the stairs to her playh...\n",
              "4      1000268201_693b08cb0e.jpg  A little girl in a pink dress going into a woo...\n",
              "...                          ...                                                ...\n",
              "40450   997722733_0cb5439472.jpg           A man in a pink shirt climbs a rock face\n",
              "40451   997722733_0cb5439472.jpg           A man is rock climbing high in the air .\n",
              "40452   997722733_0cb5439472.jpg  A person in a red shirt climbing up a rock fac...\n",
              "40453   997722733_0cb5439472.jpg                    A rock climber in a red shirt .\n",
              "40454   997722733_0cb5439472.jpg  A rock climber practices on a rock climbing wa...\n",
              "\n",
              "[40455 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5ab8b07-1eef-4a12-9601-0ff34a7b5827\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A child in a pink dress is climbing up a set o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A girl going into a wooden building .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing into a wooden playhouse .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing the stairs to her playh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl in a pink dress going into a woo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40450</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A man in a pink shirt climbs a rock face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40451</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A man is rock climbing high in the air .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40452</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A person in a red shirt climbing up a rock fac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40453</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A rock climber in a red shirt .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40454</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A rock climber practices on a rock climbing wa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40455 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5ab8b07-1eef-4a12-9601-0ff34a7b5827')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5ab8b07-1eef-4a12-9601-0ff34a7b5827 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5ab8b07-1eef-4a12-9601-0ff34a7b5827');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-939c586f-ce9c-4679-872e-519f6bd1cf47\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-939c586f-ce9c-4679-872e-519f6bd1cf47')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-939c586f-ce9c-4679-872e-519f6bd1cf47 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "df = pd.read_csv(\"data/captions.txt\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df.iloc[:7000 * 5 + 5,:]\n",
        "df_test = df.iloc[7000 * 5 + 5:,:]"
      ],
      "metadata": {
        "id": "EZkg9OCBt7_u"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "4pSWaB2fxNeg"
      },
      "outputs": [],
      "source": [
        "def plot_example(df, idx):\n",
        "    # Plot image\n",
        "    IMAGES_PATH = 'data/Images'\n",
        "    image_name = df['image'][idx * 5]\n",
        "    image = cv2.imread(os.path.join(IMAGES_PATH, image_name))\n",
        "    print(f\"Image's shape: {image.shape}\")\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    # Print captions\n",
        "    print('Captions:')\n",
        "    captions = df['caption'][5 * idx: 5 * idx + 5]\n",
        "    for idx, values in captions.items():\n",
        "        print(values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "yL7aZRIdyzyO"
      },
      "outputs": [],
      "source": [
        "# plot_example(df_train, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qU2aIFv0iNA"
      },
      "source": [
        "# Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def caption_preprocessing(text, remove_digits=True):\n",
        "    # Remove special character\n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    text = re.sub(pattern,'',text)\n",
        "\n",
        "    # Tokenize\n",
        "    text=text.split()\n",
        "\n",
        "    # Convert to lower case\n",
        "    text = [word.lower() for word in text]\n",
        "\n",
        "    # Remove tokens with numbers in them\n",
        "    text = [word for word in text if word.isalpha()]\n",
        "\n",
        "    # Store as string\n",
        "    text =  ' '.join(text)\n",
        "\n",
        "    # insert '[START]', '[END]' cho chuá»—i\n",
        "    text = '[START] ' + text + ' [END]'\n",
        "    return text\n",
        "\n",
        "print(caption_preprocessing('chao .. ban $ hello980 it\\'s a table.#'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RBQrPuZ2mAM",
        "outputId": "94c4bf2c-47b1-4130-ec9a-dc66a106f017"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[START] chao ban its a table [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df_train = df_train.copy(deep=True)\n",
        "processed_df_train['caption'] = df_train['caption'].apply(caption_preprocessing)"
      ],
      "metadata": {
        "id": "IY3v_van29ud"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = {}\n",
        "for text in processed_df_train['caption']:\n",
        "  words = text.split()\n",
        "  for w in words:\n",
        "    try:\n",
        "      word_counts[w] +=1\n",
        "    except:\n",
        "        word_counts[w] = 1\n",
        "print(len(word_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH8Oqlb53Pig",
        "outputId": "6e2c2ed7-0fd8-4df8-b009-75dc9fc9c108"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_threshold = 5\n",
        "vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
        "print('Preprocessed words %d -> %d' % (len(word_counts), len(vocab)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqqb2loo3W2W",
        "outputId": "573890ff-f8af-4963-a1ea-2e7521fe5e38"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed words 8256 -> 2762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i2w = {}\n",
        "w2i = {}\n",
        "\n",
        "id = 0\n",
        "for w in vocab:\n",
        "    w2i[w] = id\n",
        "    i2w[id] = w\n",
        "    id += 1"
      ],
      "metadata": {
        "id": "kYNHcByD3bop"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFaYF7DKp7UM"
      },
      "source": [
        "# Data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "v5lAlctySbcR"
      },
      "outputs": [],
      "source": [
        "def data_generator(df, w2i, i2w, MAX_LENGTH, VOCAB_SIZE, BATCH_SIZE):\n",
        "\n",
        "  X_image, X_cap, y = [], [], []\n",
        "  n = 0\n",
        "  while 1:\n",
        "    for i in range(len(df) // 5):\n",
        "        # Read image\n",
        "        image_name = df['image'][i * 5]\n",
        "        image = cv2.imread(os.path.join('data/Images', image_name))\n",
        "        image = cv2.resize(image, (299, 299))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        # Read captions\n",
        "        captions = df['caption'][5 * i: 5 * i + 5]\n",
        "        for idx, cap in captions.items():\n",
        "            # Encode the sequence\n",
        "            seq = [w2i[word] for word in cap.split(' ') if word in w2i]\n",
        "\n",
        "            for i in range(1, len(seq)):\n",
        "                # Split into input and output pair\n",
        "                in_seq, out_seq = seq[:i], seq[i]\n",
        "\n",
        "                # Padding input sequence\n",
        "                in_seq = pad_sequences([in_seq], maxlen=MAX_LENGTH)[0]\n",
        "\n",
        "                # Encode output sequence\n",
        "                out_seq = to_categorical([out_seq], num_classes=VOCAB_SIZE)[0]\n",
        "\n",
        "                # Store\n",
        "                n += 1\n",
        "                X_image.append(image)\n",
        "                X_cap.append(in_seq)\n",
        "                y.append(out_seq)\n",
        "\n",
        "\n",
        "                if n == BATCH_SIZE:\n",
        "                    yield ([np.array(X_image), np.array(X_cap)], np.array(y))\n",
        "                    X_image, X_cap, y = [], [], []\n",
        "                    n = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtgtXtoKqDm-"
      },
      "source": [
        "# Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "e4diKl_-3j_q"
      },
      "outputs": [],
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class ImageFeatureExtractionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, MAX_LENGTH):\n",
        "        super().__init__()\n",
        "        # Load pretrained model\n",
        "        pretrained_model = InceptionV3()\n",
        "        feature_extraction = Model(\n",
        "            pretrained_model.input, pretrained_model.layers[-2].output)\n",
        "        feature_extraction.trainable = False\n",
        "\n",
        "        # Build a model to extract feature from image\n",
        "        self.image_fe_model = Sequential([\n",
        "            Input(shape=(299, 299, 3)),\n",
        "            feature_extraction,\n",
        "            RepeatVector(MAX_LENGTH),\n",
        "            Dropout(0.2),\n",
        "        ])\n",
        "\n",
        "    def call(self, input):\n",
        "        return self.image_fe_model(input)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'image_fe_model': self.image_fe_model, })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "TfNKcXS54sqM"
      },
      "outputs": [],
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class TextFeatureExtractionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, VOCAB_SIZE, EMBEDDING_DIM, MAX_LENGTH):\n",
        "        super().__init__()\n",
        "        # Build a model to extract feature from text\n",
        "        self.text_fe_model = Sequential([\n",
        "            Input(shape=(MAX_LENGTH,)),\n",
        "            Embedding(VOCAB_SIZE, EMBEDDING_DIM, mask_zero=True),\n",
        "        ])\n",
        "\n",
        "    def call(self, input):\n",
        "        return self.text_fe_model(input)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'text_fe_model': self.text_fe_model})\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "gcTgfOm75k0M"
      },
      "outputs": [],
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, VOCAB_SIZE,\n",
        "                 EMBEDDING_DIM,\n",
        "                 MAX_LENGTH):\n",
        "        super().__init__()\n",
        "        # A decoder includes a image feature extractor and text feature extractor\n",
        "        self.image_fe = ImageFeatureExtractionLayer(MAX_LENGTH)\n",
        "\n",
        "        self.text_fe = TextFeatureExtractionLayer(\n",
        "            VOCAB_SIZE, EMBEDDING_DIM, MAX_LENGTH)\n",
        "\n",
        "        self.concat_layer = Concatenate(axis=-1)\n",
        "\n",
        "        self.model = Sequential([\n",
        "            LSTM(256),\n",
        "            Dense(256, activation='relu'),\n",
        "            Dense(VOCAB_SIZE, activation='softmax')\n",
        "        ])\n",
        "\n",
        "    def call(self, input):\n",
        "        image, text = input\n",
        "        image_fe_in = self.image_fe(image)\n",
        "        text_fe_in = self.text_fe(text)\n",
        "        concat_fe = self.concat_layer([image_fe_in, text_fe_in])\n",
        "\n",
        "        out = self.model(concat_fe)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'image_fe': self.image_fe,\n",
        "                       'text_fe': self.text_fe,\n",
        "                       'model': self.model, }\n",
        "                      )\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "7s6L_wKh0LJf"
      },
      "outputs": [],
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class Captioner(tf.keras.Model):\n",
        "    def __init__(self, w2i, i2w,\n",
        "                 VOCAB_SIZE, MAX_LENGTH,\n",
        "                 EMBEDDING_DIM,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "        self.VOCAB_SIZE = VOCAB_SIZE\n",
        "        self.MAX_LENGTH = MAX_LENGTH\n",
        "        self.EMBEDDING_DIM = EMBEDDING_DIM\n",
        "\n",
        "        self.w2i = w2i\n",
        "        self.i2w = i2w\n",
        "        self.decoder = DecoderLayer(VOCAB_SIZE, EMBEDDING_DIM, MAX_LENGTH)\n",
        "\n",
        "    def call(self, input):\n",
        "        image, sequence = input\n",
        "        pred = self.decoder([image, sequence])\n",
        "        return pred\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'i2w': self.i2w,\n",
        "            'w2i': self.w2i,\n",
        "            'decoder': self.decoder,\n",
        "            'MAX_LENGTH': self.MAX_LENGTH,\n",
        "            'VOCAB_SIZE': self.VOCAB_SIZE,\n",
        "            'EMBEDDING_DIM': self.EMBEDDING_DIM,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "    def generate_caption(self, image):\n",
        "        image = cv2.resize(image, (299, 299))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = preprocess_input(image)\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "\n",
        "        in_text = '[START]'\n",
        "        for i in range(self.MAX_LENGTH):\n",
        "            # Tokenize input\n",
        "            sequence = [self.w2i[w] for w in in_text.split() if w in self.w2i]\n",
        "\n",
        "            # Padding\n",
        "            sequence = pad_sequences([sequence], maxlen=self.MAX_LENGTH)\n",
        "\n",
        "            # Predict\n",
        "            yhat = self([image, sequence])\n",
        "            yhat = np.argmax(yhat)\n",
        "\n",
        "            # Convert index into word\n",
        "            word = self.i2w[str(yhat)]\n",
        "\n",
        "            # Add predicted word add the end of the input text\n",
        "            in_text += ' ' + word\n",
        "\n",
        "            # If word is [END] token, then break\n",
        "            if word == '[END]':\n",
        "                break\n",
        "\n",
        "        final = in_text.split()\n",
        "        final = final[1: -1]\n",
        "        final = ' '.join(final)\n",
        "\n",
        "        return final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTA3m46Wp87c"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "TGB6DefhN9ZG"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 200\n",
        "MAX_LENGTH = 40\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 16\n",
        "STEPS = len(processed_df_train) // BATCH_SIZE\n",
        "\n",
        "CHECKPOIN_PATH = 'checkpoints/par-inject-checkpoints/model-{epoch:02d}-{loss:.2f}.keras'\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "model = Captioner(w2i, i2w, VOCAB_SIZE,\n",
        "                  MAX_LENGTH, EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=optimizer)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkNm51b7SUfH",
        "outputId": "cf9e3da9-b056-4932-9855-41facd77722c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1236/2187 [===============>..............] - ETA: 3:13 - loss: 5.6775"
          ]
        }
      ],
      "source": [
        "\n",
        "my_callback = ModelCheckpoint(filepath=CHECKPOIN_PATH,\n",
        "                              save_best_only=False,\n",
        "                              verbose=1)\n",
        "\n",
        "generator = data_generator(processed_df_train, w2i, i2w,\n",
        "                           MAX_LENGTH,\n",
        "                           VOCAB_SIZE,\n",
        "                           BATCH_SIZE)\n",
        "model.fit(generator,\n",
        "          epochs=EPOCHS,\n",
        "          steps_per_epoch=STEPS,\n",
        "          verbose=1,\n",
        "          callbacks=[my_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwtE7oIXmcoL"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "model.save('models/par-inject-models/model-v1.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USjQn494wnr2"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "MzoB69XbPeYm"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "reconstructed_model = load_model('models/model-v1.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZnRp0dWK_QQ"
      },
      "outputs": [],
      "source": [
        "def evaluate_bleu_score(df, ratio, model):\n",
        "    metrics = {\n",
        "        'uni_gram': [],\n",
        "        'bi_gram': [],\n",
        "        'tri_gram': [],\n",
        "        'quad_gram': []\n",
        "    }\n",
        "    for i in tqdm(range(len(df))):\n",
        "        # Read image\n",
        "        image_name = df['image'][i * 5]\n",
        "        image = cv2.imread(os.path.join('data/Images', image_name))\n",
        "        image = cv2.resize(image, (299, 299))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        # Read captions\n",
        "        captions = df['caption'][5 * i: 5 * i + 5]\n",
        "        reference_captions = [cap[1].split() for cap in captions.items()]\n",
        "        candidate_caption = model.generate_caption(image).split()\n",
        "\n",
        "        uni = sentence_bleu(reference_captions, candidate_caption, weights=(1, 0, 0, 0))\n",
        "        bi = sentence_bleu(reference_captions, candidate_caption, weights=(0, 1, 0, 0))\n",
        "        tri = sentence_bleu(reference_captions, candidate_caption, weights=(0, 0, 1, 0))\n",
        "        quad = sentence_bleu(reference_captions, candidate_caption, weights=(0, 0, 0, 1))\n",
        "\n",
        "        metrics['uni_gram'].append(uni)\n",
        "        metrics['bi_gram'].append(bi)\n",
        "        metrics['tri_gram'].append(tri)\n",
        "        metrics['quad_gram'].append(quad)\n",
        "\n",
        "\n",
        "    metrics['uni_gram'] = sum(metrics['uni_gram']) / len(metrics['uni_gram'])\n",
        "    metrics['bi_gram'] = sum(metrics['bi_gram']) / len(metrics['bi_gram'])\n",
        "    metrics['tri_gram'] = sum(metrics['tri_gram']) / len(metrics['tri_gram'])\n",
        "    metrics['quad_gram'] = sum(metrics['quad_gram']) / len(metrics['quad_gram'])\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_bleu_score(df_test, reconstructed_model)"
      ],
      "metadata": {
        "id": "hMwh7bs0HCtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "zcMr5f4WHcgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_A6pjFdLtMYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrHDywq5mWHj"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "zrZGRqWuvzm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "dedf6854-9f99-4cdd-8c5e-edb547889827"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'in inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable inflatable'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "image = cv2.imread('data/Images/997722733_0cb5439472.jpg')\n",
        "reconstructed_model.generate_caption(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJPQTnMellZ4"
      },
      "outputs": [],
      "source": [
        "# Plot image\n",
        "idx = 45\n",
        "image_name = df['image'][idx * 5]\n",
        "image = cv2.imread(os.path.join('data/Images', image_name))\n",
        "cv2_imshow(image)\n",
        "\n",
        "# Print captions\n",
        "print('Captions:')\n",
        "captions = df['caption'][5 * idx: 5 * idx + 5]\n",
        "for idx, values in captions.items():\n",
        "    print(values)\n",
        "\n",
        "print(\"Predicted caption:\")\n",
        "print(model.generate_caption(image))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0SQbciCCz0x_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AY1QLpUixcq-",
        "5qU2aIFv0iNA",
        "oFaYF7DKp7UM",
        "WtgtXtoKqDm-",
        "USjQn494wnr2"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}